name: ETL News (cron + manual)

on:
  schedule:
    - cron: "0 22 * * *"   # 22:00 UTC ≈ 5:00 pm Bogotá
  workflow_dispatch: {}

jobs:
  etl:
    runs-on: ubuntu-latest
    env:
      CONTAINER: datasets
      DEST_ROOT: news

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r news_etl/requirements.txt
          pip install pyyaml

      # Este paso es opcional si tu ETL crea la carpeta por sí solo.
      - name: Prepare data dir
        run: mkdir -p data

      - name: Run ETL (genera CSVs y heartbeat en data/)
        env:
          AZURE_LANGUAGE_KEY: ${{ secrets.AZURE_LANGUAGE_KEY }}
          AZURE_LANGUAGE_ENDPOINT: ${{ secrets.AZURE_LANGUAGE_ENDPOINT }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
          SAMPLE_LIMIT: "0"
        run: |
          python -m news_etl.news_etl --config news_etl/config.yaml

      - name: Upload CSVs + heartbeat to Azure Blob (datasets/news/)
        uses: azure/cli@v2
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        with:
          inlineScript: |
            # Crear contenedor si no existe
            az storage container create \
              --name "$CONTAINER" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" 1>/dev/null

            # Subir CSVs (solo los news_*.csv u otros que genere tu ETL)
            az storage blob upload-batch \
              --destination "$CONTAINER" \
              --source data \
              --pattern "news_*.csv*" \
              --destination-path "$DEST_ROOT" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
              --overwrite

            # Subir heartbeat
            if [ -f data/heartbeat.txt ]; then
              az storage blob upload \
                --container-name "$CONTAINER" \
                --file data/heartbeat.txt \
                --name "$DEST_ROOT/heartbeat.txt" \
                --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
                --overwrite
            fi
