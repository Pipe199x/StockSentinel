name: ETL News (cron + manual)

on:
  schedule:
    - cron: "15 12 * * *"  # 12:15 UTC, ajústalo si quieres
  workflow_dispatch: {}

jobs:
  etl_news:
    runs-on: ubuntu-latest

    env:
      CONTAINER: datasets
      DEST_ROOT: news
      PYTHON_VERSION: "3.11"
      TICKERS: "AMZN,MSFT,GOOGL"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r news_etl/requirements.txt
          pip install pyyaml requests

      - name: Sanity check NEWSAPI_KEY
        shell: bash
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
        run: |
          set -euo pipefail
          echo "NEWSAPI_KEY length: ${#NEWSAPI_KEY}"
          RESP="$(curl -sS --get "https://newsapi.org/v2/everything" \
            --data-urlencode "q=Amazon" \
            --data-urlencode "language=en" \
            --data-urlencode "pageSize=1" \
            --data-urlencode "apiKey=${NEWSAPI_KEY}")"
          python - <<'PY'
import json,sys
j=json.loads(sys.stdin.read())
print("Ping status:", j.get("status","NA"))
PY
          :

      - name: Prepare data dir
        run: mkdir -p data

      - name: Generate raw with NewsAPI (con fallback)
        shell: bash
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
          TICKERS: ${{ env.TICKERS }}
        run: |
          set -euo pipefail
          echo "== Plan A: news_client =="
          if python -m news_etl.news_client \
                --out data/news_raw.ndjson \
                --tickers "$TICKERS" \
                --language en; then
            :
          else
            echo "news_client falló; seguimos al fallback..." >&2
          fi

          if [ ! -s data/news_raw.ndjson ]; then
            echo "== Plan B: fallback a NewsAPI desde Python =="
            python - <<'PY'
import os, sys, json, datetime as dt, requests
API_KEY = os.environ["NEWSAPI_KEY"]
tickers = [t.strip() for t in os.environ.get("TICKERS","").split(",") if t.strip()]
QMAP = {
  "AMZN": "(Amazon OR AWS OR Alexa)",
  "MSFT": "(Microsoft OR Windows OR Xbox OR Azure)",
  "GOOGL": "(Google OR Alphabet OR Android OR YouTube OR Gemini)",
}
until = dt.datetime.utcnow()
since = until - dt.timedelta(days=3)
def fetch(q, page):
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": q,
        "language": "en",
        "from": since.isoformat(timespec="seconds")+"Z",
        "to": until.isoformat(timespec="seconds")+"Z",
        "sortBy": "publishedAt",
        "pageSize": 100,
        "page": page,
        "apiKey": API_KEY,
    }
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    return r.json()
seen = set()
out_path = "data/news_raw.ndjson"
count = 0
with open(out_path, "w", encoding="utf-8") as f:
    for t in tickers:
        q = QMAP.get(t, t)
        for page in (1, 2):
            try:
                data = fetch(q, page)
            except Exception as e:
                print(f"[WARN] fetch {t} p{page}: {e}", file=sys.stderr)
                continue
            if data.get("status") != "ok":
                print(f"[WARN] status != ok: {data}", file=sys.stderr)
                continue
            for a in data.get("articles", []):
                url = (a.get("url") or "").strip()
                if not url or url in seen:
                    continue
                seen.add(url)
                item = {
                    "published_at": a.get("publishedAt"),
                    "source": (a.get("source") or {}).get("name"),
                    "title": a.get("title"),
                    "lang": "en",
                    "url": url,
                }
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
                count += 1
print(f"[fallback] escritos {count} items")
if count == 0:
    print("ERROR: fallback no obtuvo resultados.", file=sys.stderr)
    sys.exit(4)
PY
          fi

          echo "=== data/ ==="
          ls -l data
          test -s data/news_raw.ndjson || { echo "ERROR: no existe/está vacío data/news_raw.ndjson"; exit 4; }

      - name: Run ETL
        env:
          AZURE_LANGUAGE_KEY: ${{ secrets.AZURE_LANGUAGE_KEY }}
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
          SAMPLE_LIMIT: "0"
        run: |
          set -euo pipefail
          python -m news_etl.news_etl --config news_etl/config.yaml
          echo "=== data/ tras ETL ==="
          ls -l data

      - name: Upload CSVs + heartbeat to Azure Blob (datasets/news/)
        uses: azure/cli@v2
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        with:
          inlineScript: |
            set -euo pipefail
            az storage container create \
              --name "$CONTAINER" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" 1>/dev/null
            az storage blob upload-batch \
              --destination "$CONTAINER" \
              --source data \
              --pattern "*.csv*" \
              --destination-path "$DEST_ROOT" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
              --overwrite
            az storage blob upload \
              --container-name "$CONTAINER" \
              --file data/heartbeat.txt \
              --name "$DEST_ROOT/heartbeat.txt" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
              --overwrite

      - name: Cleanup local raw
        if: always()
        run: |
          rm -f data/news_raw.ndjson || true
          echo "RAW eliminado."
