name: ETL News (cron + manual)

on:
  schedule:
    - cron: "15 12 * * *"      # diario 12:15 UTC (ajústalo)
  workflow_dispatch: {}

jobs:
  etl_news:
    runs-on: ubuntu-latest
    env:
      CONTAINER: datasets
      DEST_ROOT: news
      PYTHON_VERSION: "3.11"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r news_etl/requirements.txt
          pip install pyyaml

      - name: Prepare data dir
        run: mkdir -p data

      # ---------- Ping mínimo para verificar NewsAPI ----------
      - name: Sanity check NEWSAPI
        shell: bash
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
        run: |
          set -euo pipefail
          if [[ -z "${NEWSAPI_KEY:-}" ]]; then
            echo "NEWSAPI_KEY vacío o faltante"; exit 2
          fi
          echo "NEWSAPI_KEY length: ${#NEWSAPI_KEY}"
          sudo apt-get update -y >/dev/null
          sudo apt-get install -y jq >/dev/null
          RESP=$(curl -sS --get "https://newsapi.org/v2/everything" \
            --data-urlencode "q=Amazon" \
            --data-urlencode "language=en" \
            --data-urlencode "pageSize=1" \
            --data-urlencode "apiKey=${NEWSAPI_KEY}")
          echo "Ping status:  $(echo "$RESP" | jq -r '.status   // "NA"')"
          echo "Ping code:    $(echo "$RESP" | jq -r '.code     // "NA"')"
          echo "Ping message: $(echo "$RESP" | jq -r '.message  // "NA"')"

      # ---------- DEBUG FUERTE de news_client ----------
      - name: Generate raw with NewsAPI (debug fuerte)
        shell: bash
        env:
          NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
        run: |
          set -euo pipefail
          echo "== Ejecutando news_client (intento #1) =="
          set -x
          python -m news_etl.news_client \
            --out data/news_raw.ndjson \
            --tickers AMZN,MSFT,GOOGL \
            --language en \
            1>client_stdout.log 2>client_stderr.log || echo "news_client devolvió código $?"
          set +x

          echo "== Exit codes y logs =="
          echo "stdout (últimas 200 líneas):"
          tail -n 200 client_stdout.log || true
          echo "stderr (últimas 200 líneas):"
          tail -n 200 client_stderr.log || true

          echo "== Listado de data/ tras intento #1 =="
          ls -l data || true

          if [[ ! -s data/news_raw.ndjson ]]; then
            echo "No se generó RAW en el intento #1 — reintentando con ventana más amplia..."
            # Reintento: algunos clientes filtran por fecha muy reciente y quedan en 0 resultados
            # (si tu news_client soporta --from_days o similar, úsalo; si no, esta llamada es igual al #1)
            set -x
            python -m news_etl.news_client \
              --out data/news_raw.ndjson \
              --tickers AMZN,MSFT,GOOGL \
              --language en \
              1>>client_stdout.log 2>>client_stderr.log || echo "news_client (reintento) devolvió código $?"
            set +x

            echo "== Listado de data/ tras intento #2 =="
            ls -l data || true
          fi

          if [[ -s data/news_raw.ndjson ]]; then
            echo "RAW OK. Primeras líneas:"
            head -n 5 data/news_raw.ndjson || true
          else
            echo "ERROR: No se generó data/news_raw.ndjson (faltante o vacío) luego de 2 intentos."
            echo "Pistas típicas:"
            echo " - El módulo news_client pudo filtrar demasiado (fecha/fuentes) y devolvió 0."
            echo " - news_client pudo necesitar flags adicionales (p. ej. ventana de días)."
            echo " - Si la salida es a stdout (no a archivo), habría que ajustar news_client para escribir --out."
            echo "Revisa los logs arriba (stdout/stderr)."
            exit 4
          fi

      - name: Run ETL
        env:
          AZURE_LANGUAGE_ENDPOINT: ${{ secrets.AZURE_LANGUAGE_ENDPOINT }}
          AZURE_LANGUAGE_KEY: ${{ secrets.AZURE_LANGUAGE_KEY }}
          SAMPLE_LIMIT: "0"
        run: |
          set -euo pipefail
          test -s data/news_raw.ndjson || { echo "Falta data/news_raw.ndjson"; exit 1; }
          python -m news_etl.news_etl --config news_etl/config.yaml
          echo "=== Contenido de data/ tras ETL ==="
          ls -l data

      - name: Upload CSVs + heartbeat to Azure Blob (datasets/news/)
        uses: azure/cli@v2
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        with:
          inlineScript: |
            set -euo pipefail
            az storage container create \
              --name "$CONTAINER" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" 1>/dev/null

            az storage blob upload-batch \
              --destination "$CONTAINER" \
              --source data \
              --pattern "*.csv*" \
              --destination-path "$DEST_ROOT" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
              --overwrite

            az storage blob upload \
              --container-name "$CONTAINER" \
              --file data/heartbeat.txt \
              --name "$DEST_ROOT/heartbeat.txt" \
              --connection-string "$AZURE_STORAGE_CONNECTION_STRING" \
              --overwrite

      - name: Cleanup local raw
        if: always()
        run: rm -f data/news_raw.ndjson || true
